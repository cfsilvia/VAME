# Project configurations
Project: Your-VAME-Project
model_name: VAME
n_cluster: 15
pose_confidence: 0.99

# Project path and videos
project_path: 
  F:\SilviaData\ScriptOnGithub\VAME\vame\working_directory\Your-VAME-Project-Jul15-2025/
video_sets:
- video-1

# Data
all_data: yes

# Creation of train set:
egocentric_data:
robust: true
iqr_factor: 4
axis:
savgol_filter: true
savgol_length: 5
savgol_order: 2
test_fraction: 0.1

# RNN model general hyperparameter:
pretrained_model: None
pretrained_weights: false
num_features: 12
batch_size: 256
max_epochs: 500
model_snapshot: 50
model_convergence: 50
transition_function: GRU
beta: 1
beta_norm: false
zdims: 30
learning_rate: 0.0005
time_window: 30
prediction_decoder: 1
prediction_steps: 15
noise: false
scheduler: 1
scheduler_step_size: 100
scheduler_gamma: 0.2
    #Note the optimal scheduler threshold below can vary greatly (from .1-.0001) between experiments. 
    #You are encouraged to read the torch.optim.ReduceLROnPlateau docs to understand the threshold to use.
scheduler_threshold:
softplus: false

# Segmentation:
parameterization: hmm
hmm_trained: false
load_data: -PE-seq-clean
individual_parameterization: false
random_state_kmeans: 42
n_init_kmeans: 15

# Video writer:
length_of_motif_video: 1000

# UMAP parameter:
min_dist: 0.1
n_neighbors: 200
random_state: 42
num_points: 30000

# ONLY CHANGE ANYTHING BELOW IF YOU ARE FAMILIAR WITH RNN MODELS
# RNN encoder hyperparamter:
hidden_size_layer_1: 256
hidden_size_layer_2: 256
dropout_encoder: 0

# RNN reconstruction hyperparameter:
hidden_size_rec: 256
dropout_rec: 0
n_layers: 1

# RNN prediction hyperparamter:
hidden_size_pred: 256
dropout_pred: 0

# RNN loss hyperparameter:
mse_reconstruction_reduction: sum
mse_prediction_reduction: sum
kmeans_loss: 30
kmeans_lambda: 0.1
anneal_function: linear
kl_start: 2
annealtime: 4

# Legacy mode
legacy: false
